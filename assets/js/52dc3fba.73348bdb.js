"use strict";(self.webpackChunkmanurukavina=self.webpackChunkmanurukavina||[]).push([[525],{7607:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>t});var s=n(8583),a=n(4848),l=n(8453);const r={slug:"asm-audio",title:"Audio Wave Processing in Assembly"},o=void 0,d={authorsImageUrls:[]},t=[{value:"Understanding Audio Waveforms",id:"understanding-audio-waveforms",level:2},{value:"Processing Audio in Assembly",id:"processing-audio-in-assembly",level:2},{value:"1. Loading Audio Data",id:"1-loading-audio-data",level:3},{value:"2. Applying Basic Audio Effects",id:"2-applying-basic-audio-effects",level:3},{value:"a) Volume Control (Scaling Amplitude)",id:"a-volume-control-scaling-amplitude",level:4},{value:"b) Echo Effect (Delayed Addition)",id:"b-echo-effect-delayed-addition",level:4},{value:"3. FFT for Frequency Analysis",id:"3-fft-for-frequency-analysis",level:3},{value:"4. Writing Processed Audio Back",id:"4-writing-processed-audio-back",level:3},{value:"Optimizing Performance",id:"optimizing-performance",level:2}];function c(e){const i={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.p,{children:"Audio processing at the assembly level was a cool challenge, merging DSP principles with the  control of low-level programming. here is how i did some stuff:"}),"\n",(0,a.jsx)(i.h2,{id:"understanding-audio-waveforms",children:"Understanding Audio Waveforms"}),"\n",(0,a.jsx)(i.p,{children:"Audio waves are typically represented as sequences of digital samples, which are discrete values representing the amplitude of the sound at a given time. These samples can be:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"8-bit, 16-bit, or 32-bit integers"})," (PCM format)"]}),"\n",(0,a.jsx)(i.li,{children:(0,a.jsx)(i.strong,{children:"Floating-point values"})}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Compressed formats (MP3, AAC)"}),", which require additional decoding steps"]}),"\n"]}),"\n",(0,a.jsx)(i.p,{children:"For assembly-level processing, we generally deal with PCM data, which is stored as signed or unsigned integers."}),"\n",(0,a.jsx)(i.h2,{id:"processing-audio-in-assembly",children:"Processing Audio in Assembly"}),"\n",(0,a.jsx)(i.h3,{id:"1-loading-audio-data",children:"1. Loading Audio Data"}),"\n",(0,a.jsx)(i.p,{children:"Before performing any processing, the audio file (e.g., WAV format) must be read into memory. This typically involves:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"Parsing the WAV header to extract sample rate, bit depth, and number of channels"}),"\n",(0,a.jsx)(i.li,{children:"Allocating a buffer to hold raw PCM data"}),"\n",(0,a.jsxs)(i.li,{children:["Using system calls (like ",(0,a.jsx)(i.code,{children:"read"})," in Linux or ",(0,a.jsx)(i.code,{children:"ReadFile"})," in Windows) to load the data"]}),"\n"]}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-assembly",children:"; Example: x86-64 NASM to read a file into a buffer\nmov rdi, file_descriptor    ; File descriptor\nmov rsi, buffer            ; Destination buffer\nmov rdx, buffer_size       ; Number of bytes to read\nsyscall                    ; Invoke system call (Linux)\n"})}),"\n",(0,a.jsx)(i.h3,{id:"2-applying-basic-audio-effects",children:"2. Applying Basic Audio Effects"}),"\n",(0,a.jsx)(i.h4,{id:"a-volume-control-scaling-amplitude",children:"a) Volume Control (Scaling Amplitude)"}),"\n",(0,a.jsx)(i.p,{children:"To increase or decrease volume, we scale each sample by a factor:"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-assembly",children:"; Assuming 16-bit signed PCM data in an array\nmov ax, [buffer]          ; Load sample\nimul ax, volume_factor    ; Scale amplitude\nsar ax, 8                 ; Normalize (assuming factor is 8-bit fixed point)\nmov [buffer], ax          ; Store modified sample\n"})}),"\n",(0,a.jsx)(i.h4,{id:"b-echo-effect-delayed-addition",children:"b) Echo Effect (Delayed Addition)"}),"\n",(0,a.jsx)(i.p,{children:"An echo effect can be implemented by mixing delayed samples with the original waveform:"}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-assembly",children:"; Simple echo: y[n] = x[n] + 0.5 * x[n - delay]\nmov ax, [buffer + delay]   ; Fetch old sample\nsar ax, 1                  ; Scale by 0.5\nadd [buffer], ax           ; Mix with current sample\n"})}),"\n",(0,a.jsx)(i.h3,{id:"3-fft-for-frequency-analysis",children:"3. FFT for Frequency Analysis"}),"\n",(0,a.jsxs)(i.p,{children:["For frequency-domain processing (e.g., equalizers, reverb), we use the ",(0,a.jsx)(i.strong,{children:"Fast Fourier Transform (FFT)"}),". Implementing FFT in assembly involves:"]}),"\n",(0,a.jsxs)(i.ol,{children:["\n",(0,a.jsx)(i.li,{children:"Bit-reversal permutation of input samples"}),"\n",(0,a.jsx)(i.li,{children:"Iterative butterfly operations for DFT computation"}),"\n",(0,a.jsx)(i.li,{children:"Applying windowing and scaling as needed"}),"\n"]}),"\n",(0,a.jsxs)(i.p,{children:["Though a full FFT implementation is complex, an optimized ",(0,a.jsx)(i.strong,{children:"SIMD (Single Instruction, Multiple Data) approach"})," using ",(0,a.jsx)(i.strong,{children:"AVX or SSE"})," instructions can significantly speed up processing."]}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-assembly",children:"; Simplified SSE-based addition of two audio sample arrays\nmovaps xmm0, [buffer1]   ; Load 4 float samples\nmovaps xmm1, [buffer2]   ; Load another set\naddps xmm0, xmm1         ; Perform parallel addition\nmovaps [buffer_out], xmm0 ; Store result\n"})}),"\n",(0,a.jsx)(i.h3,{id:"4-writing-processed-audio-back",children:"4. Writing Processed Audio Back"}),"\n",(0,a.jsx)(i.p,{children:"After processing, the modified PCM data must be written back to an output file. This follows the same procedure as reading but in reverse:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:"Open a new file for writing"}),"\n",(0,a.jsx)(i.li,{children:"Write the WAV header"}),"\n",(0,a.jsx)(i.li,{children:"Write PCM data using system calls"}),"\n"]}),"\n",(0,a.jsx)(i.pre,{children:(0,a.jsx)(i.code,{className:"language-assembly",children:"; Write buffer to file\nmov rdi, output_fd       ; Output file descriptor\nmov rsi, buffer          ; Buffer containing PCM data\nmov rdx, buffer_size     ; Number of bytes to write\nsyscall                  ; Invoke write system call\n"})}),"\n",(0,a.jsx)(i.h2,{id:"optimizing-performance",children:"Optimizing Performance"}),"\n",(0,a.jsx)(i.p,{children:"Since audio processing is computationally intensive, optimization techniques include:"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:(0,a.jsx)(i.strong,{children:"Using SIMD instructions (SSE/AVX) for parallel processing"})}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Loop unrolling"})," to reduce branching overhead"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Efficient memory access"})," to minimize cache misses"]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Fixed-point arithmetic"})," to avoid floating-point overhead on low-power systems"]}),"\n"]}),"\n",(0,a.jsx)(i.p,{children:"Thanks for reading :)"})]})}function u(e={}){const{wrapper:i}={...(0,l.R)(),...e.components};return i?(0,a.jsx)(i,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8583:e=>{e.exports=JSON.parse('{"permalink":"/blog/asm-audio","source":"@site/blog/2025-03-17-asm-audio.md","title":"Audio Wave Processing in Assembly","description":"Audio processing at the assembly level was a cool challenge, merging DSP principles with the  control of low-level programming. here is how i did some stuff:","date":"2025-03-17T00:00:00.000Z","tags":[],"readingTime":2.865,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"asm-audio","title":"Audio Wave Processing in Assembly"},"unlisted":false}')}}]);