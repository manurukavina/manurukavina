"use strict";(self.webpackChunkmanurukavina=self.webpackChunkmanurukavina||[]).push([[130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"asm-audio","metadata":{"permalink":"/blog/asm-audio","source":"@site/blog/2025-03-17-asm-audio.md","title":"Audio Wave Processing in Assembly","description":"Audio processing at the assembly level was a cool challenge, merging DSP principles with the  control of low-level programming. here is how i did some stuff:","date":"2025-03-17T00:00:00.000Z","tags":[],"readingTime":2.865,"hasTruncateMarker":true,"authors":[],"frontMatter":{"slug":"asm-audio","title":"Audio Wave Processing in Assembly"},"unlisted":false},"content":"Audio processing at the assembly level was a cool challenge, merging DSP principles with the  control of low-level programming. here is how i did some stuff:\\n\\n\x3c!-- truncate --\x3e\\n\\n## Understanding Audio Waveforms\\n\\nAudio waves are typically represented as sequences of digital samples, which are discrete values representing the amplitude of the sound at a given time. These samples can be:\\n- **8-bit, 16-bit, or 32-bit integers** (PCM format)\\n- **Floating-point values**\\n- **Compressed formats (MP3, AAC)**, which require additional decoding steps\\n\\nFor assembly-level processing, we generally deal with PCM data, which is stored as signed or unsigned integers.\\n\\n## Processing Audio in Assembly\\n\\n### 1. Loading Audio Data\\n\\nBefore performing any processing, the audio file (e.g., WAV format) must be read into memory. This typically involves:\\n- Parsing the WAV header to extract sample rate, bit depth, and number of channels\\n- Allocating a buffer to hold raw PCM data\\n- Using system calls (like `read` in Linux or `ReadFile` in Windows) to load the data\\n\\n```assembly\\n; Example: x86-64 NASM to read a file into a buffer\\nmov rdi, file_descriptor    ; File descriptor\\nmov rsi, buffer            ; Destination buffer\\nmov rdx, buffer_size       ; Number of bytes to read\\nsyscall                    ; Invoke system call (Linux)\\n```\\n\\n### 2. Applying Basic Audio Effects\\n\\n#### a) Volume Control (Scaling Amplitude)\\nTo increase or decrease volume, we scale each sample by a factor:\\n\\n```assembly\\n; Assuming 16-bit signed PCM data in an array\\nmov ax, [buffer]          ; Load sample\\nimul ax, volume_factor    ; Scale amplitude\\nsar ax, 8                 ; Normalize (assuming factor is 8-bit fixed point)\\nmov [buffer], ax          ; Store modified sample\\n```\\n\\n#### b) Echo Effect (Delayed Addition)\\nAn echo effect can be implemented by mixing delayed samples with the original waveform:\\n\\n```assembly\\n; Simple echo: y[n] = x[n] + 0.5 * x[n - delay]\\nmov ax, [buffer + delay]   ; Fetch old sample\\nsar ax, 1                  ; Scale by 0.5\\nadd [buffer], ax           ; Mix with current sample\\n```\\n\\n### 3. FFT for Frequency Analysis\\nFor frequency-domain processing (e.g., equalizers, reverb), we use the **Fast Fourier Transform (FFT)**. Implementing FFT in assembly involves:\\n1. Bit-reversal permutation of input samples\\n2. Iterative butterfly operations for DFT computation\\n3. Applying windowing and scaling as needed\\n\\nThough a full FFT implementation is complex, an optimized **SIMD (Single Instruction, Multiple Data) approach** using **AVX or SSE** instructions can significantly speed up processing.\\n\\n```assembly\\n; Simplified SSE-based addition of two audio sample arrays\\nmovaps xmm0, [buffer1]   ; Load 4 float samples\\nmovaps xmm1, [buffer2]   ; Load another set\\naddps xmm0, xmm1         ; Perform parallel addition\\nmovaps [buffer_out], xmm0 ; Store result\\n```\\n\\n### 4. Writing Processed Audio Back\\nAfter processing, the modified PCM data must be written back to an output file. This follows the same procedure as reading but in reverse:\\n- Open a new file for writing\\n- Write the WAV header\\n- Write PCM data using system calls\\n\\n```assembly\\n; Write buffer to file\\nmov rdi, output_fd       ; Output file descriptor\\nmov rsi, buffer          ; Buffer containing PCM data\\nmov rdx, buffer_size     ; Number of bytes to write\\nsyscall                  ; Invoke write system call\\n```\\n\\n## Optimizing Performance\\nSince audio processing is computationally intensive, optimization techniques include:\\n- **Using SIMD instructions (SSE/AVX) for parallel processing**\\n- **Loop unrolling** to reduce branching overhead\\n- **Efficient memory access** to minimize cache misses\\n- **Fixed-point arithmetic** to avoid floating-point overhead on low-power systems\\n\\nThanks for reading :)"}]}}')}}]);